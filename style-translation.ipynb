{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Style translation"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport torch\nimport torchvision\nfrom torchvision import models, transforms\nfrom tqdm.notebook import tqdm\nimport os\nimport shutil\nimport matplotlib.pyplot as plt\nfrom skimage import io, transform\nimport itertools\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass PhotoMonetDataset(Dataset):\n\n    def __init__(self, photo_path, monet_path):\n        if not os.path.exists(photo_path):\n            raise ValueError(f'{photo_path} does not exist')\n        if not os.path.exists(monet_path):\n            raise ValueError(f'{monet_path} does not exist')\n        self.photo = photo_path\n        self.monet = monet_path\n        self.photo_names = sorted(os.listdir(self.photo))\n        self.monet_names = sorted(os.listdir(self.monet))\n\n    def __len__(self):\n        return max(len(self.photo_names), len(self.monet_names))\n\n    def __getitem__(self, idx):\n        assert type(idx) == int\n        \n        n_photo = len(self.photo_names)\n        n_monet = len(self.monet_names)\n        \n        if n_photo > n_monet:\n            i_photo = idx\n            i_monet = idx % n_monet\n        else:\n            i_photo = idx % n_photo\n            i_monet = idx\n        \n        photo_name = self.photo_names[i_photo]\n        monet_name = self.monet_names[i_monet]\n        \n        def get_image(path, filename):\n            image = io.imread(os.path.join(path, filename))\n            return transforms.ToTensor()(image) * 2.0 - 1.0\n        \n        return get_image(self.photo, photo_name), get_image(self.monet, monet_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = PhotoMonetDataset(\n    photo_path='../input/gan-getting-started/photo_jpg',\n    monet_path='../input/gan-getting-started/monet_jpg',\n)\n\ndataloader = torch.utils.data.DataLoader(\n    dataset, batch_size=16, shuffle=True, num_workers=8\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def downsample(in_channels, out_channels, size, apply_instancenorm=True):\n    layers = []\n    layers.append(torch.nn.Conv2d(in_channels, out_channels, size, stride=2, padding=1, bias=False))\n\n    if apply_instancenorm:\n        layers.append(torch.nn.InstanceNorm2d(out_channels))\n\n    layers.append(torch.nn.LeakyReLU())\n\n    return torch.nn.Sequential(*layers).to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def upsample(in_channels, out_channels, size, apply_dropout=False):\n    layers = []\n    layers.append(torch.nn.ConvTranspose2d(in_channels, out_channels, size, stride=2, padding=1, bias=False))\n\n    layers.append(torch.nn.InstanceNorm2d(out_channels))\n\n    if apply_dropout:\n        layers.append(torch.nn.Dropout(0.5))\n\n    layers.append(torch.nn.ReLU())\n\n    return torch.nn.Sequential(*layers).to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"OUTPUT_CHANNELS = 3\n\nclass Generator(torch.nn.Module):\n\n    def __init__(self):\n        super(Generator, self).__init__()\n        \n        # bs = batch size\n        self.down_stack = [\n            downsample(3, 64, 4, apply_instancenorm=False), # (bs, 128, 128, 64)\n            downsample(64, 128, 4), # (bs, 64, 64, 128)\n            downsample(128, 256, 4), # (bs, 32, 32, 256)\n            downsample(256, 512, 4), # (bs, 16, 16, 512)\n            downsample(512, 512, 4), # (bs, 8, 8, 512)\n            downsample(512, 512, 4), # (bs, 4, 4, 512)\n            downsample(512, 512, 4), # (bs, 2, 2, 512)\n            downsample(512, 512, 4), # (bs, 1, 1, 512)\n        ]\n\n        self.up_stack = [\n            upsample(512, 512, 4, apply_dropout=True), # (bs, 2, 2, 1024)\n            upsample(1024, 512, 4, apply_dropout=True), # (bs, 4, 4, 1024)\n            upsample(1024, 512, 4, apply_dropout=True), # (bs, 8, 8, 1024)\n            upsample(1024, 512, 4), # (bs, 16, 16, 1024)\n            upsample(1024, 256, 4), # (bs, 32, 32, 512)\n            upsample(512, 128, 4), # (bs, 64, 64, 256)\n            upsample(256, 64, 4), # (bs, 128, 128, 128)\n        ]\n\n        self.last = torch.nn.ConvTranspose2d(128, OUTPUT_CHANNELS, 4,\n                                             stride=2, padding=1).to(device) # (bs, 256, 256, 3)\n        self.tanh = torch.nn.Tanh()\n\n    def forward(self, x):\n        skips = []\n        for down in self.down_stack:\n            x = down(x)\n            skips.append(x)\n\n        skips = reversed(skips[:-1])\n\n        for up, skip in zip(self.up_stack, skips):\n            x = up(x)\n            x = torch.cat([x, skip], dim=1)\n\n        x = self.tanh(self.last(x))\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Discriminator(torch.nn.Module):\n\n    def __init__(self):\n        super(Discriminator, self).__init__()\n\n        self.down1 = downsample(3, 64, 4, False)\n        self.down2 = downsample(64, 128, 4)\n        self.down3 = downsample(128, 256, 4)\n\n        self.zero_pad1 = torch.nn.ZeroPad2d(1)\n        self.conv = torch.nn.Conv2d(256, 512, 4, stride=1, bias=False)\n\n        self.norm1 = torch.nn.InstanceNorm2d(512)\n        self.leaky_relu = torch.nn.LeakyReLU()\n\n        self.zero_pad2 = torch.nn.ZeroPad2d(1)\n        self.last = torch.nn.Conv2d(512, 1, 4, stride=1)\n    \n    def forward(self, x):\n        x = self.down1(x)\n        x = self.down2(x)\n        x = self.down3(x)\n        \n        x = self.zero_pad1(x)\n        x = self.conv(x)\n        \n        x = self.norm1(x)\n        x = self.leaky_relu(x)\n        \n        x = self.zero_pad2(x)\n        x = self.last(x)\n        \n        return x\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def discriminator_loss(real, generated):\n    real = torch.nn.Sigmoid()(real)\n    generated = torch.nn.Sigmoid()(generated)\n    real_loss = torch.nn.BCELoss(reduction='mean')(real, torch.ones_like(real))\n    generated_loss = torch.nn.BCELoss(reduction='mean')(generated, torch.zeros_like(generated))\n    total_disc_loss = real_loss + generated_loss\n    return total_disc_loss * 0.5\n\ndef generator_loss(generated):\n    generated = torch.nn.Sigmoid()(generated)\n    return torch.nn.BCELoss(reduction='mean')(generated, torch.ones_like(generated))\n\ndef calc_cycle_loss(real_image, cycled_image, LAMBDA):\n    loss1 = torch.mean(torch.abs(real_image - cycled_image))\n    return LAMBDA * loss1\n\ndef identity_loss(real_image, same_image, LAMBDA):\n    loss = torch.mean(torch.abs(real_image - same_image))\n    return LAMBDA * 0.5 * loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CycleGAN:\n    \n    def __init__(self, lm, epochs, dataloader):\n        self.lm = lm\n        self.epochs = epochs\n        self.dataloader = dataloader\n        self.monet_gen = Generator().to(device)\n        self.photo_gen = Generator().to(device)\n        self.monet_disc = Discriminator().to(device)\n        self.photo_disc = Discriminator().to(device)\n        self.gen_opt = torch.optim.Adam(itertools.chain(self.monet_gen.parameters(), self.photo_gen.parameters()))\n        self.disc_opt = torch.optim.Adam(itertools.chain(self.monet_disc.parameters(), self.photo_disc.parameters()))\n        \n    def generator_pass(self, real_photo, real_monet):\n        fake_monet = self.monet_gen(real_photo)\n        cycled_photo = self.photo_gen(fake_monet)\n\n        fake_photo = self.photo_gen(real_monet)\n        cycled_monet = self.monet_gen(fake_photo)\n\n        same_monet = self.monet_gen(real_monet)\n        same_photo = self.photo_gen(real_photo)\n\n        disc_real_monet = self.monet_disc(real_monet)\n        disc_real_photo = self.photo_disc(real_photo)\n\n        disc_fake_monet = self.monet_disc(fake_monet)\n        disc_fake_photo = self.photo_disc(fake_photo)\n\n        monet_gen_loss = generator_loss(disc_fake_monet)\n        photo_gen_loss = generator_loss(disc_fake_photo)\n\n        total_gen_loss = monet_gen_loss + photo_gen_loss \\\n            + calc_cycle_loss(real_monet, cycled_monet, self.lm) \\\n            + calc_cycle_loss(real_photo, cycled_photo, self.lm) \\\n            + identity_loss(real_monet, same_monet, self.lm) + identity_loss(real_photo, same_photo, self.lm)\n    \n        return total_gen_loss\n\n    def discriminator_pass(self, real_photo, real_monet):\n        fake_monet = self.monet_gen(real_photo)\n        fake_photo = self.photo_gen(real_monet)\n\n        same_monet = self.monet_gen(real_monet)\n        same_photo = self.photo_gen(real_photo)\n\n        disc_real_monet = self.monet_disc(real_monet)\n        disc_real_photo = self.photo_disc(real_photo)\n\n        disc_fake_monet = self.monet_disc(fake_monet)\n        disc_fake_photo = self.photo_disc(fake_photo)\n\n        monet_disc_loss = discriminator_loss(disc_real_monet, disc_fake_monet)\n        photo_disc_loss = discriminator_loss(disc_real_photo, disc_fake_photo)\n    \n        return (monet_disc_loss + photo_disc_loss) * 0.5\n\n    def train(self):\n        for i in range(self.epochs):\n            print(f\"epoch {i+1} / {self.epochs}\")\n            for (real_photo, real_monet) in tqdm(self.dataloader):\n                real_photo, real_monet = real_photo.to(device), real_monet.to(device)\n                \n                self.gen_opt.zero_grad()\n                \n                gen_loss = self.generator_pass(real_photo, real_monet)\n                gen_loss.backward()\n                \n                self.gen_opt.step()\n                \n                self.disc_opt.zero_grad()\n\n                disc_loss = self.discriminator_pass(real_photo, real_monet)\n                \n                disc_loss.backward()\n                self.disc_opt.step()\n                \n                print(f\"gen loss: {gen_loss.item():.5f}, disc loss: {disc_loss.item():.5f}\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gan = CycleGAN(lm=10, epochs=15, dataloader=dataloader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gan.train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unnorm(img):\n    return img.add(1.0).mul(0.5)\n\nplt.figure(figsize=(7, 16))\nfor i in range(5):\n    photo_img, _ = next(iter(dataloader))\n    pred_monet = gan.monet_gen(photo_img.to(device)).cpu().detach()\n    photo_img = unnorm(photo_img)\n    pred_monet = unnorm(pred_monet)\n\n    plt.subplot(5, 2, i*2 + 1)\n    plt.imshow(photo_img[0].permute(1, 2, 0))\n    plt.title(\"Input Photo\")\n    plt.axis(\"off\")\n    \n    plt.subplot(5, 2, i*2 + 2)\n    plt.imshow(pred_monet[0].permute(1, 2, 0))\n    plt.title(\"Monet-esque Photo\")\n    plt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! mkdir ../images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unnorm(img):\n    return img.add(1.0).mul(0.5)\n\ntrans = transforms.ToPILImage()\n\ni = 1\nfor batch in tqdm(dataloader):\n    photos, _ = batch\n    monets = gan.monet_gen(photos.to(device)).cpu().detach()\n    monets = unnorm(monets)\n    for monet in monets:\n        img = trans(monet).convert(\"RGB\")\n        img.save(\"../images/image\" + str(i) + \".jpg\")\n        i += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shutil.make_archive(\"images\", 'zip', \"../images\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}